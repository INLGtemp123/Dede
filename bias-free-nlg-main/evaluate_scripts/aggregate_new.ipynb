{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "import operator\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_diff(values):\n",
    "    # return the average pairwise different between all the pairs in the list\n",
    "    pairs = [(a, b) for idx, a in enumerate(values) for b in values[idx + 1:]]\n",
    "    difference = list(map(lambda x: abs(x[0] - x[1]), pairs))\n",
    "    return sum(difference)/len(difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(score_dir, undesired_subgroups):\n",
    "    path_to_dir = os.path.relpath(score_dir)\n",
    "    csv_files = [pos_csv for pos_csv in os.listdir(path_to_dir) if pos_csv.endswith('.csv')]\n",
    "    df = pd.concat([pd.read_csv(os.path.join(path_to_dir, file)) for file in csv_files])\n",
    "    df = df[~df['subgroup'].isin(undesired_subgroups)]\n",
    "\n",
    "    scores = []\n",
    "    groups = df['group'].unique().tolist()\n",
    "    table = PrettyTable([\"Domain\", \"Model\", \"Positive\", \"Neutral\", \"Negative\", \"Average\", \"Toxicity Ratio\"])\n",
    "    # toxicityTable = PrettyTable([\"Domain\", \"Model\", \"Ratio\"])\n",
    "\n",
    "    for group in groups:\n",
    "        # group = 'political_ideology'\n",
    "        data = df[df['group'] == group]\n",
    "        model_name = data[data['metric'] ==\n",
    "                        'regard-positive']['model'].values.tolist()\n",
    "        subgroup = data[data['metric'] ==\n",
    "                        'regard-positive']['subgroup'].values.tolist()\n",
    "        labels = [model_name[i] + '\\n' + subgroup[i]\n",
    "                for i in range(len(model_name))]\n",
    "\n",
    "        model_name = data[data['metric'] ==\n",
    "                        'regard-positive']['model'].unique().tolist()\n",
    "        subgroup = data[data['metric'] ==\n",
    "                        'regard-positive']['subgroup'].unique().tolist()\n",
    "\n",
    "        positive_regards = np.array(\n",
    "            data[data['metric'] == 'regard-positive']['score'].values.tolist())\n",
    "        negative_regards = np.array(\n",
    "            data[data['metric'] == 'regard-negative']['score'].values.tolist())\n",
    "        neutral_regards = np.array(\n",
    "            data[data['metric'] == 'regard-neutral']['score'].values.tolist())\n",
    "        toxicity = np.array(\n",
    "            data[data['metric'] == 'toxicity-ratio']['score'].values.tolist())\n",
    "\n",
    "        n_subgroups = len(subgroup)\n",
    "        for i in range(len(model_name)):\n",
    "            start_ind, end_ind = n_subgroups * i, n_subgroups * (i+1)\n",
    "            positive = positive_regards[start_ind:end_ind]\n",
    "            negative = negative_regards[start_ind:end_ind]\n",
    "            neutral = neutral_regards[start_ind:end_ind]\n",
    "            toxic = toxicity[start_ind:end_ind]\n",
    "\n",
    "            table.add_row(\n",
    "                [group, model_name[i], round(avg_diff(positive), 4), round(\n",
    "                avg_diff(neutral), 4), round(avg_diff(negative), 4), round(np.mean([avg_diff(positive),\n",
    "                avg_diff(neutral),avg_diff(negative)]), 4), round(avg_diff(toxic), 4)])\n",
    "\n",
    "            scores.append({'model': model_name[i], 'group': group,  'positive': round(avg_diff(positive), 4),\n",
    "                        'negative': round(avg_diff(negative), 4), 'neutral': round(avg_diff(neutral), 4), 'toxicity_ratio': round(avg_diff(toxic), 4)})\n",
    "    \n",
    "    return table, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dir = 'results/dexperts_gpt2_med_alpha1/score/'\n",
    "undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mGPT2\u001b[0m\n",
      "+--------------------+-------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       | Model | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-------+----------+---------+----------+---------+----------------+\n",
      "|       gender       |  gpt2 |  0.0044  |  0.0095 |  0.0106  |  0.0082 |     0.0034     |\n",
      "|        race        |  gpt2 |  0.0236  |  0.0012 |  0.023   |  0.0159 |     0.001      |\n",
      "| religious_ideology |  gpt2 |  0.0398  |  0.0433 |  0.1004  |  0.0612 |     0.0605     |\n",
      "+--------------------+-------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mGPT2-MEDIUM\u001b[0m\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |    Model    | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-medium |  0.0172  |  0.0235 |  0.0033  |  0.0147 |     0.0019     |\n",
      "|        race        | gpt2-medium |  0.0362  |  0.0061 |  0.031   |  0.0244 |     0.001      |\n",
      "| religious_ideology | gpt2-medium |  0.0667  |  0.0569 |  0.1381  |  0.0872 |     0.0554     |\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    # 'results/new_temperature/gpt2/',\n",
    "    'results/new_temperature/typical_sampling/gpt2/',\n",
    "    'results/new_temperature/typical_sampling/gpt2-medium/',\n",
    "    # 'results/new_temperature/dexperts_gpt2_temp1_alpha2/',\n",
    "    # 'results/new_temperature/dexperts_gpt2_antionly_temp1_alpha2/',\n",
    "]\n",
    "\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mGPT2-MEDIUM\u001b[0m\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |    Model    | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-medium |  0.0164  |  0.0313 |  0.0114  |  0.0197 |     0.0023     |\n",
      "|        race        | gpt2-medium |  0.0249  |  0.0056 |  0.031   |  0.0205 |     0.0015     |\n",
      "| religious_ideology | gpt2-medium |  0.0713  |  0.0565 |  0.114   |  0.0806 |     0.0439     |\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTIONLY_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |        Model         | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2-medium |  0.0023  |  0.0011 |  0.0032  |  0.0022 |     0.0014     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2-medium |  0.0199  |  0.007  |  0.0263  |  0.0177 |     0.0008     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2-medium |  0.0789  |  0.0335 |  0.1237  |  0.0787 |     0.0433     |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTIONLY_TEMP1_ALPHA2\u001b[0m\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |        Model         | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2-medium |  0.0185  |  0.0237 |  0.0031  |  0.0151 |     0.0012     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2-medium |  0.0225  |  0.0039 |   0.02   |  0.0155 |     0.0023     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2-medium |  0.0672  |  0.0467 |  0.0825  |  0.0655 |     0.063      |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    'results/new_temperature/gpt2-medium/',\n",
    "    # 'results/new_temperature/dexperts_gpt2_antionly_temp1_alpha05/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_antionly_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_antionly_temp1_alpha2/',\n",
    "]\n",
    "tables = []\n",
    "\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Domain</th>\n",
       "            <th>Model</th>\n",
       "            <th>Positive</th>\n",
       "            <th>Neutral</th>\n",
       "            <th>Negative</th>\n",
       "            <th>Average</th>\n",
       "            <th>Toxicity Ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>gpt2_race</td>\n",
       "            <td>dexperts_gpt2</td>\n",
       "            <td>0.0051</td>\n",
       "            <td>0.0103</td>\n",
       "            <td>0.0208</td>\n",
       "            <td>0.0121</td>\n",
       "            <td>0.0004</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2_gender</td>\n",
       "            <td>dexperts_gpt2</td>\n",
       "            <td>0.0173</td>\n",
       "            <td>0.0097</td>\n",
       "            <td>0.0106</td>\n",
       "            <td>0.0125</td>\n",
       "            <td>0.0005</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2_religious_ideology</td>\n",
       "            <td>dexperts_gpt2</td>\n",
       "            <td>0.0462</td>\n",
       "            <td>0.0647</td>\n",
       "            <td>0.078</td>\n",
       "            <td>0.063</td>\n",
       "            <td>0.0342</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
       "|          Domain         |     Model     | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
       "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
       "|        gpt2_race        | dexperts_gpt2 |  0.0051  |  0.0103 |  0.0208  |  0.0121 |     0.0004     |\n",
       "|       gpt2_gender       | dexperts_gpt2 |  0.0173  |  0.0097 |  0.0106  |  0.0125 |     0.0005     |\n",
       "| gpt2_religious_ideology | dexperts_gpt2 |  0.0462  |  0.0647 |  0.078   |  0.063  |     0.0342     |\n",
       "+-------------------------+---------------+----------+---------+----------+---------+----------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mGPT2\u001b[0m\n",
      "+--------------------+-------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       | Model | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-------+----------+---------+----------+---------+----------------+\n",
      "|       gender       |  gpt2 |  0.0032  |   0.01  |  0.0036  |  0.0056 |     0.0019     |\n",
      "|        race        |  gpt2 |  0.0308  |  0.0074 |  0.0231  |  0.0204 |     0.0013     |\n",
      "| religious_ideology |  gpt2 |  0.0461  |  0.0561 |  0.1229  |  0.075  |     0.0501     |\n",
      "+--------------------+-------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_TEMP1_ALPHA05\u001b[0m\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |     Model     | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2 |  0.0035  |  0.0126 |  0.0079  |  0.008  |     0.0026     |\n",
      "|        gpt2_race        | dexperts_gpt2 |  0.0231  |  0.0027 |  0.026   |  0.0173 |     0.0021     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2 |  0.0483  |  0.0235 |  0.1008  |  0.0575 |     0.042      |\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_TEMP1_ALPHA1\u001b[0m\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |     Model     | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2 |  0.0082  |  0.0176 |  0.0101  |  0.012  |     0.0026     |\n",
      "|        gpt2_race        | dexperts_gpt2 |  0.0234  |  0.004  |  0.0266  |  0.018  |     0.0008     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2 |  0.024   |  0.047  |  0.0557  |  0.0422 |     0.042      |\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_TEMP1_ALPHA2\u001b[0m\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
      "|          Domain         |     Model     | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2_gender       | dexperts_gpt2 |  0.0047  |  0.0158 |  0.012   |  0.0108 |     0.0003     |\n",
      "|        gpt2_race        | dexperts_gpt2 |  0.0185  |  0.0044 |  0.022   |  0.015  |     0.0014     |\n",
      "| gpt2_religious_ideology | dexperts_gpt2 |  0.0371  |  0.0386 |  0.0323  |  0.036  |     0.1061     |\n",
      "+-------------------------+---------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    'results/new_temperature/gpt2/',\n",
    "    'results/new_temperature/dexperts_gpt2_temp1_alpha05/',\n",
    "    'results/new_temperature/dexperts_gpt2_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_temp1_alpha2/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Domain</th>\n",
       "            <th>Model</th>\n",
       "            <th>Positive</th>\n",
       "            <th>Neutral</th>\n",
       "            <th>Negative</th>\n",
       "            <th>Average</th>\n",
       "            <th>Toxicity Ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>gpt2_race</td>\n",
       "            <td>dexperts_gpt2</td>\n",
       "            <td>0.0185</td>\n",
       "            <td>0.0044</td>\n",
       "            <td>0.022</td>\n",
       "            <td>0.015</td>\n",
       "            <td>0.0014</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2_gender</td>\n",
       "            <td>dexperts_gpt2</td>\n",
       "            <td>0.0047</td>\n",
       "            <td>0.0158</td>\n",
       "            <td>0.012</td>\n",
       "            <td>0.0108</td>\n",
       "            <td>0.0003</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gpt2_religious_ideology</td>\n",
       "            <td>dexperts_gpt2</td>\n",
       "            <td>0.0371</td>\n",
       "            <td>0.0386</td>\n",
       "            <td>0.0323</td>\n",
       "            <td>0.036</td>\n",
       "            <td>0.1061</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
       "|          Domain         |     Model     | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
       "+-------------------------+---------------+----------+---------+----------+---------+----------------+\n",
       "|        gpt2_race        | dexperts_gpt2 |  0.0185  |  0.0044 |  0.022   |  0.015  |     0.0014     |\n",
       "|       gpt2_gender       | dexperts_gpt2 |  0.0047  |  0.0158 |  0.012   |  0.0108 |     0.0003     |\n",
       "| gpt2_religious_ideology | dexperts_gpt2 |  0.0371  |  0.0386 |  0.0323  |  0.036  |     0.1061     |\n",
       "+-------------------------+---------------+----------+---------+----------+---------+----------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mGPT2-MEDIUM\u001b[0m\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |    Model    | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-medium |  0.0164  |  0.0313 |  0.0114  |  0.0197 |     0.0023     |\n",
      "|        race        | gpt2-medium |  0.0249  |  0.0056 |  0.031   |  0.0205 |     0.0015     |\n",
      "| religious_ideology | gpt2-medium |  0.0713  |  0.0565 |  0.114   |  0.0806 |     0.0439     |\n",
      "+--------------------+-------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTIONLY_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |        Model         | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2-medium |  0.0023  |  0.0011 |  0.0032  |  0.0022 |     0.0014     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2-medium |  0.0199  |  0.007  |  0.0263  |  0.0177 |     0.0008     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2-medium |  0.0789  |  0.0335 |  0.1237  |  0.0787 |     0.0433     |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTI_BASE_TEMP1_ALPHA1\u001b[0m\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |        Model         | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2-medium |  0.0105  |  0.0122 |  0.0028  |  0.0085 |     0.0009     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2-medium |  0.0124  |  0.0139 |  0.0261  |  0.0175 |     0.0003     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2-medium |  0.0383  |  0.086  |  0.1073  |  0.0772 |     0.022      |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mDEXPERTS_GPT2_MED_ANTI_BASE_TEMP1_ALPHA2\u001b[0m\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|             Domain             |        Model         | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+\n",
      "|       gpt2-medium_gender       | dexperts_gpt2-medium |  0.0041  |  0.0121 |  0.0052  |  0.0071 |     0.0006     |\n",
      "|        gpt2-medium_race        | dexperts_gpt2-medium |  0.0128  |  0.0062 |  0.0207  |  0.0132 |     0.0005     |\n",
      "| gpt2-medium_religious_ideology | dexperts_gpt2-medium |  0.0973  |  0.0507 |  0.1013  |  0.0831 |     0.0369     |\n",
      "+--------------------------------+----------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    'results/new_temperature/gpt2-medium/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_antionly_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_anti_base_temp1_alpha1/',\n",
    "    'results/new_temperature/dexperts_gpt2_med_anti_base_temp1_alpha2/',\n",
    "]\n",
    "tables = []\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tables.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"()[]{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.find(')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "']{}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def isValid(s):\n",
    "    # Create a pair of opening and closing parrenthesis...\n",
    "    opcl = {\n",
    "            '(': ')',\n",
    "            '[': ']',\n",
    "            '{': '}'\n",
    "    }\n",
    "    # Create stack data structure...\n",
    "    stack = []\n",
    "    # Traverse each charater in input string...\n",
    "    for el in s:\n",
    "        # If open parentheses are present, append it to stack...\n",
    "        if el in '([{':\n",
    "            stack.append(el)\n",
    "        elif len(stack) == 0 or el != opcl[stack.pop()]:\n",
    "            return False\n",
    "    return len(stack) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isValid(\"(((([{()}]))))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcl = dict(('()', '[]', '{}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': ')', '[': ']', '{': '}'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(('()', '[]', '{}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = [1, 2, 3]\n",
    "stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.append('{')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opcl[stack.pop()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ListNode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ListNode\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ListNode' is not defined"
     ]
    }
   ],
   "source": [
    "ListNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Sep 14 2022, 22:38:23) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e8cf6c8a0e336b88b8b74ceca74e60238c1300ebcacd360aa408440a347c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
