{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "import operator\n",
    "from colorama import Fore, Back, Style\n",
    "from utils import avg_diff, get_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mGPT2-FINETUNED-RELIGION-REDDITBIAS\u001b[0m\n",
      "+--------------------+------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |               Model                | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-finetuned-religion-redditbias |  0.0306  |  0.0349 |  0.0676  |  0.0444 |     0.0028     |\n",
      "|        race        | gpt2-finetuned-religion-redditbias |  0.0306  |  0.0158 |  0.0512  |  0.0325 |     0.0066     |\n",
      "| religious_ideology | gpt2-finetuned-religion-redditbias |  0.0412  |  0.0301 |  0.1003  |  0.0572 |     0.0931     |\n",
      "+--------------------+------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    # \"results/new_temperature/gpt2\",\n",
    "    # \"results/new_temperature/reddit-race-bias\",\n",
    "    \"results/new_temperature/expert_models/gpt2-finetuned-religion-redditbias\",\n",
    "]\n",
    "tabs = []\n",
    "\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    tabs.append(table)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Domain</th>\n",
       "            <th>Model</th>\n",
       "            <th>Positive</th>\n",
       "            <th>Neutral</th>\n",
       "            <th>Negative</th>\n",
       "            <th>Average</th>\n",
       "            <th>Toxicity Ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>gender</td>\n",
       "            <td>gpt2-finetuned-religion-reddit-antibias</td>\n",
       "            <td>0.0369</td>\n",
       "            <td>0.0328</td>\n",
       "            <td>0.0044</td>\n",
       "            <td>0.0247</td>\n",
       "            <td>0.0023</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>race</td>\n",
       "            <td>gpt2-finetuned-religion-reddit-antibias</td>\n",
       "            <td>0.037</td>\n",
       "            <td>0.0167</td>\n",
       "            <td>0.0189</td>\n",
       "            <td>0.0242</td>\n",
       "            <td>0.0041</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>religious_ideology</td>\n",
       "            <td>gpt2-finetuned-religion-reddit-antibias</td>\n",
       "            <td>0.0261</td>\n",
       "            <td>0.0471</td>\n",
       "            <td>0.0992</td>\n",
       "            <td>0.0575</td>\n",
       "            <td>0.0397</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
       "|       Domain       |                  Model                  | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
       "+--------------------+-----------------------------------------+----------+---------+----------+---------+----------------+\n",
       "|       gender       | gpt2-finetuned-religion-reddit-antibias |  0.0369  |  0.0328 |  0.0044  |  0.0247 |     0.0023     |\n",
       "|        race        | gpt2-finetuned-religion-reddit-antibias |  0.037   |  0.0167 |  0.0189  |  0.0242 |     0.0041     |\n",
       "| religious_ideology | gpt2-finetuned-religion-reddit-antibias |  0.0261  |  0.0471 |  0.0992  |  0.0575 |     0.0397     |\n",
       "+--------------------+-----------------------------------------+----------+---------+----------+---------+----------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mREDDIT-GENDER-BIAS\u001b[0m\n",
      "+--------------------+---------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |              Model              | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+---------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | pt2-finetuned-gender-redditbias |  0.0048  |  0.0064 |  0.0035  |  0.0049 |     0.0046     |\n",
      "|        race        | pt2-finetuned-gender-redditbias |  0.0254  |  0.0078 |  0.0152  |  0.0161 |     0.0005     |\n",
      "| religious_ideology | pt2-finetuned-gender-redditbias |  0.0263  |  0.0563 |  0.0815  |  0.0547 |     0.0559     |\n",
      "+--------------------+---------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mREDDIT-GENDER-ANTIBIAS\u001b[0m\n",
      "+--------------------+-----------------------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |            Model            | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-----------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-reddit-gender-antibias |  0.0146  |  0.0104 |  0.0052  |  0.0101 |     0.0028     |\n",
      "|        race        | gpt2-reddit-gender-antibias |  0.0231  |  0.0059 |  0.0193  |  0.0161 |     0.0023     |\n",
      "| religious_ideology | gpt2-reddit-gender-antibias |  0.042   |  0.0851 |  0.1261  |  0.0844 |     0.0552     |\n",
      "+--------------------+-----------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    \"results/new_temperature/reddit-gender-bias\",\n",
    "    \"results/new_temperature/reddit-gender-antibias\",\n",
    "]\n",
    "\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mREDDIT-RACE-BIAS\u001b[0m\n",
      "+--------------------+--------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |             Model              | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+--------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-finetuned-race-redditbias |  0.0126  |  0.0083 |  0.0032  |  0.008  |     0.0034     |\n",
      "|        race        | gpt2-finetuned-race-redditbias |  0.0193  |  0.0008 |  0.0214  |  0.0138 |     0.0017     |\n",
      "| religious_ideology | gpt2-finetuned-race-redditbias |  0.0295  |  0.0452 |  0.1057  |  0.0601 |     0.0367     |\n",
      "+--------------------+--------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n",
      "\u001b[91mREDDIT-RACE-ANTIBIAS\u001b[0m\n",
      "+--------------------+-------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       Domain       |                Model                | Positive | Neutral | Negative | Average | Toxicity Ratio |\n",
      "+--------------------+-------------------------------------+----------+---------+----------+---------+----------------+\n",
      "|       gender       | gpt2-finetuned-race-reddit-antibias |  0.0014  |  0.0078 |  0.0053  |  0.0048 |     0.0024     |\n",
      "|        race        | gpt2-finetuned-race-reddit-antibias |  0.0233  |  0.0006 |  0.0236  |  0.0158 |     0.0026     |\n",
      "| religious_ideology | gpt2-finetuned-race-reddit-antibias |  0.0589  |  0.0403 |  0.1045  |  0.0679 |     0.0399     |\n",
      "+--------------------+-------------------------------------+----------+---------+----------+---------+----------------+ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "directories = [\n",
    "    \"results/new_temperature/reddit-race-bias\",\n",
    "    \"results/new_temperature/reddit-race-antibias\",\n",
    "]\n",
    "\n",
    "for score_dir in directories:\n",
    "    score_dir = os.path.join(score_dir, 'score/')\n",
    "    undesired_subgroups = ['Asian_Americans', 'Hispanic_and_Latino_Americans', 'hinduism', 'buddhism', 'sikhism', 'atheism']\n",
    "    table, scores = get_results(score_dir, undesired_subgroups)\n",
    "    print(f\"{Fore.LIGHTRED_EX}{score_dir.split('/')[-3].upper()}{Style.RESET_ALL}\")\n",
    "    print(table.get_string(sort_key=operator.itemgetter(1, 0), sortby=\"Domain\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e8cf6c8a0e336b88b8b74ceca74e60238c1300ebcacd360aa408440a347c3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
